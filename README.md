# Agentic Research Prototyping

A comprehensive, rigorous research workflow system for foundational AI models using specialized agents.

## Overview

This system provides a complete workflow from literature review to publication-ready research, preventing common methodological failures like circular logic, unvalidated measures, and non-reproducible results.

### Key Features

- âœ… **4 Specialized Agents** - Clear separation of concerns
- âœ… **Prevents Circular Logic** - Automated detection and blocking
- âœ… **Flexible Validation** - Expert annotation or rigorous alternatives
- âœ… **Pre-specified Analysis** - Prevents p-hacking and HARKing
- âœ… **Multi-stage Review** - 5 comprehensive review stages
- âœ… **Fully Reproducible** - Complete documentation and verification

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RESEARCH AGENT SYSTEM                         â”‚
â”‚                  4 Specialized Agents                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Agent 1: RESEARCH SCOUT ğŸ”
â”œâ”€ Literature review
â”œâ”€ Gap identification
â””â”€ Research question formulation
    â†“
Agent 2: METHODOLOGY ARCHITECT ğŸ—ï¸
â”œâ”€ Methodology design
â”œâ”€ Validation strategy (expert or alternative)
â”œâ”€ Circular logic detection
â””â”€ Statistical analysis plan
    â†“
Agent 3: EXPERIMENT EXECUTOR âš™ï¸
â”œâ”€ Ground truth collection
â”œâ”€ Measure validation (blocks until validated)
â”œâ”€ Experiment execution
â””â”€ Quality control
    â†“
Agent 4: RESULTS ANALYST & REVIEWER ğŸ“Š
â”œâ”€ Statistical analysis
â”œâ”€ Honest interpretation
â”œâ”€ Multi-stage review (5 stages)
â””â”€ Publication preparation
```

## Quick Start

### 1. Understand the System

Read the documentation in order:

1. **[AGENT_SYSTEM.md](docs/AGENT_SYSTEM.md)** - System overview and architecture
2. **[RESEARCH_WORKFLOW.md](docs/RESEARCH_WORKFLOW.md)** - Complete workflow with all phases
3. **[VALIDATION_OPTIONS.md](docs/VALIDATION_OPTIONS.md)** - Validation strategies when experts unavailable

### 2. Review Agent Skills

Each agent has a detailed skill document:

- **[Research Scout Agent](agents/research-scout-agent.md)** - Literature review and gap identification
- **[Methodology Architect Agent](agents/methodology-architect-agent.md)** - Methodology design and validation planning
- **[Experiment Executor Agent](agents/experiment-executor-agent.md)** - Validation execution and experiments
- **[Results Analyst & Reviewer Agent](agents/results-analyst-reviewer-agent.md)** - Analysis and comprehensive review

### 3. Use the Skills

Skills are organized by research phase:

- **[Literature Review Skill](skills/literature-review-skill/)** - Systematic literature search and synthesis
- **[Research Methodology Validator](skills/research-methodology-validator/)** - Prevents circular logic, enforces validation
- **[Validation Without Humans Skill](skills/validation-without-humans-skill/)** - Alternative validation strategies
- **[Experiment Design Skill](skills/experiment-design-skill/)** - Rigorous experiment design
- **[Results Analysis Skill](skills/results-analysis-skill/)** - Statistical analysis with effect sizes
- **[Research Review Skill](skills/research-review-skill/)** - Multi-stage review process

## Timeline

| Phase | Agent | Duration | Output |
|-------|-------|----------|--------|
| 1. Literature Review | Research Scout | 2-4 weeks | Research questions |
| 2. Methodology Design | Methodology Architect | 2-3 weeks | Methodology + validation plan |
| 3. Validation & Experiments | Experiment Executor | 5-7 weeks | Validated data |
| 4. Analysis & Review | Results Analyst & Reviewer | 3-4 weeks | Publication-ready research |

**Total: 12-18 weeks (3-4.5 months)**

## Key Principles

### 1. No Circular Logic

The system automatically detects and prevents circular validation:

```python
# Agent 2: Methodology Architect
circular_check = self.check_circular_logic(validation_strategy)

if circular_check['has_circular_logic']:
    raise ValueError("CANNOT PROCEED - Redesign validation")
```

### 2. Mandatory Validation

All measures must be validated before use:

```python
# Agent 3: Experiment Executor
measure.validate_against_ground_truth(ground_truth)

if not measure.is_validated:
    raise ValueError("Cannot use unvalidated measure")
```

### 3. Pre-specified Analysis

Statistical analysis plan must be written before data collection:

```python
# Agent 2: Methodology Architect
analysis_plan = self.prespecify_statistical_analysis()
# Prevents p-hacking and HARKing
```

### 4. Honest Reporting

All results must be reported, not just significant ones:

```python
# Agent 4: Results Analyst & Reviewer
if self.is_overclaiming(interpretation):
    raise ValueError("Overclaiming detected - revise interpretation")
```

## Validation Strategies

### Expert Annotation (Preferred)

- **Confidence:** HIGH
- **Cost:** $3k-9k
- **Time:** 2-3 months
- **Requirements:** nâ‰¥100, â‰¥3 experts, Îºâ‰¥0.7

### Alternative Validation (When Experts Unavailable)

1. **Behavioral Ground Truth** - Use actual outcomes (MEDIUM confidence)
2. **Comparative Validation** - Compare to established measures (MEDIUM confidence)
3. **Crowdsourced Validation** - Many non-experts with quality control (MEDIUM confidence)
4. **Hybrid Approach** - Small expert + large behavioral (MEDIUM-HIGH confidence) â­ **Recommended**
5. **Multiple Strategies** - Combine 2-3 approaches (MEDIUM-HIGH confidence) â­ **Best**

See [VALIDATION_OPTIONS.md](docs/VALIDATION_OPTIONS.md) for complete details.

## Quality Gates

Each phase has mandatory quality gates:

### Gate 1: After Literature Review
- [ ] Comprehensive search completed
- [ ] Gaps validated (genuine, significant, feasible, novel)
- [ ] Research questions formulated

### Gate 2: After Methodology Design
- [ ] Constructs clearly defined
- [ ] Validation strategy independent (NO circular logic)
- [ ] Statistical plan pre-specified

### Gate 3: After Validation & Experiments
- [ ] All measures validated (F1â‰¥0.7 or equivalent)
- [ ] Pilot successful
- [ ] Data verified

### Gate 4: After Analysis & Review
- [ ] Pre-specified plan followed
- [ ] Effect sizes with CIs reported
- [ ] All 5 review stages passed
- [ ] Independent reproduction successful

## Multi-Stage Review

Agent 4 conducts 5 comprehensive review stages:

1. **Methodology Review** - Constructs, validation, circular logic check
2. **Implementation Review** - Code quality, reproducibility
3. **Results Review** - Statistical validity, effect sizes, honest interpretation
4. **Contribution Review** - Novelty, significance, quality
5. **Reproducibility Review** - Independent verification

All stages must be approved before publication.

## Example Usage

```python
# Initialize orchestrator
orchestrator = ResearchOrchestrator()

# Run complete research workflow
research_interest = "Self-correction mechanisms in large language models"

final_output = orchestrator.run_research_workflow(research_interest)

if final_output['status'] == 'approved_for_publication':
    print("âœ“ Research ready for publication!")
    print(f"Publication package: {final_output['publication_package']}")
else:
    print("âš ï¸ Revisions needed")
    for issue in final_output['remaining_issues']:
        print(f"  - {issue}")
```

## Documentation Structure

```
agentic-research-prototyping/
â”œâ”€â”€ README.md (this file)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ AGENT_SYSTEM.md (system architecture)
â”‚   â”œâ”€â”€ RESEARCH_WORKFLOW.md (complete workflow)
â”‚   â””â”€â”€ VALIDATION_OPTIONS.md (validation strategies)
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ research-scout-agent.md
â”‚   â”œâ”€â”€ methodology-architect-agent.md
â”‚   â”œâ”€â”€ experiment-executor-agent.md
â”‚   â””â”€â”€ results-analyst-reviewer-agent.md
â”œâ”€â”€ skills/
â”‚   â”œâ”€â”€ literature-review-skill/
â”‚   â”œâ”€â”€ research-methodology-validator/
â”‚   â”œâ”€â”€ validation-without-humans-skill/
â”‚   â”œâ”€â”€ experiment-design-skill/
â”‚   â”œâ”€â”€ results-analysis-skill/
â”‚   â””â”€â”€ research-review-skill/
â””â”€â”€ examples/
    â””â”€â”€ (coming soon)
```

## Common Pitfalls Prevented

| Pitfall | Prevention |
|---------|-----------|
| Circular validation | Methodology Architect detects, requires independent ground truth |
| Unvalidated measures | Experiment Executor blocks usage until validated |
| P-hacking | Pre-specified analysis plan enforced |
| HARKing | Hypotheses documented before data collection |
| Overclaiming | Results Analyst checks interpretation |
| Non-reproducible | Reproducibility review with independent verification |
| Cherry-picking | All results must be reported |
| Missing effect sizes | Analysis skill requires them |

## Contributing

This system is designed for rigorous research in foundational AI models. Contributions welcome:

- Additional validation strategies
- Example implementations
- Case studies
- Improvements to detection algorithms

## License

MIT License - See LICENSE file for details

## Citation

If you use this system in your research, please cite:

```bibtex
@software{agentic_research_prototyping,
  title = {Agentic Research Prototyping: A Rigorous Workflow for Foundational AI Models},
  author = {Baena, E.},
  year = {2025},
  url = {https://github.com/ebaenamar/agentic-research-prototyping}
}
```

## Contact

For questions or issues, please open a GitHub issue.

---

**Status:** Active Development

**Last Updated:** October 2025
